version 1.0

## Copyright Wellcome Sanger Institute, Oxford University, and the Broad Institute 2020
##
## This WDL pipeline implements CNV Coverage Calls portion of the vector Copy Number Variation Pipeline as described in:
## https://github.com/malariagen/pipelines/blob/add_cnv_vector_spec/docs/specs/cnv-vector.md
##.

import "../../../structs/gcp/RunTimeSettings.wdl"
import "../../../tasks/gcp/Tasks.wdl" as Tasks
import "../../../tasks/gcp/StatisticalPhasingTasks.wdl" as StatisticalPhasingTasks

workflow CNVCoverageCalls {
  String pipeline_version = "1.0.0"

  ## Sub-pipeline: CNV Coverage Calls

#### Step: CNV Coverage Calls
**Description:** Uses the predicted copy number state values generated by the HMM to call CNVs. Calls CNVs based on the change in predicted copy number within consecutive windows. Calls variants by grouping CNVs observed in multiple samples, as determined by the start and end coordinates. \
**Inputs:** Copy number state files. 1 per window per sample.\
**Outputs:** File similar to VCF. Lists variants with genotypes for each sample. 1 per sample set.\
**Software:** R version 3.6.1\
Steps in CNV_pipeline/scripts/coverage_CNVs_vobs.sh\
```bash
R-3.6.1 --slave -f $scriptsfolder/CNV_analysis.r --args $chrom \
                                                        $manifest \
                                                        $coverage_variance_file \
                                                        $gene_coordinates_file \
                                                        $detox_genes_file \
                                                        $workingfolder \
                                                        $ncores \
                                                        $outputfolder \
                                                        $metadata \
                                                        > $coveragefolder/$chrom/CNV_analysis_logs/CNV_analysis_${output_name}.log 2>&1
```

  input {
    String project_id
    String sample_name
    File input_bam
    File input_bam_index

    File CNV_HMM_output

    RunTimeSettings runTimeSettings
    String runtime_zones
  }

  String output_basename = project_id + "_" + sample_name

  # Step 1: Extract Diagnostic Reads
  call TargetRegionsTasks.ExtractDiagnosticReads as ExtractDiagnosticReads {
    input:
      input_bam = input_bam,
      input_bam_index = input_bam_index,
      project_id = project_id,
      output_basename = output_basename,
      runTimeSettings = runTimeSettings,
      runtime_zones = runtime_zones
  }

  # Step 2: Target Regions CNV calling
  call TargetRegionsTasks.TargetRegionsCNVCalling as CNVCalling {
    input:
      HMM = CNV_HMM_output,
      discordant_reads = ExtractDiagnosticReads.discordant_reads_output,
      breakpoint_reads = ExtractDiagnosticReads.breakpoint_reads_output,
      output_basename = output_basename,
      runTimeSettings = runTimeSettings,
      runtime_zones = runtime_zones
  }

  meta {
    allowNestedInputs: true
  }

  output {
    File output_file = CNVCalling.output_file
  }
}

task ExtractDiagnosticReads {
  input {
    File input_bam
    File input_bam_index
    String project_id
    String output_basename

    String docker = "us.gcr.io/broad-gotc-prod/cnv:1.0.0-1679431881"
    Int num_cpu = 1
    RunTimeSettings runTimeSettings
    Int preemptible_tries = runTimeSettings.preemptible_tries
    String runtime_zones = "us-central1-b"
    Float mem_gb = 3.75
    Int disk_gb = 50
  }

  command <<<
    # Get the discordant reads
    # Runs SSFA.py for every chromosome: This script goes through an alignment file and records the positions of reads within a specified region whose mates map to a different chromosome or discordantly on the same chromosome
    SSFA_script=$scriptsfolder/SSFA.py
    SSFAfolder=$outputfolder/diagnostic_reads/SSFA
    python $SSFA_script $bamfile 2R 3425000:3650000 ${SSFAfolder}/2R/Ace1_region/${samplename}_Ace1_SSFA_output.csv 10 > ${SSFAfolder}/2R/Ace1_region/SSFAlogs/${samplename}_Ace1_SSFA_output.log 2>&1
    python $SSFA_script $bamfile 2R 28460000:28570000 ${SSFAfolder}/2R/Cyp6_region/${samplename}_CYP6_SSFA_output.csv 10 > ${SSFAfolder}/2R/Cyp6_region/SSFAlogs/${samplename}_CYP6_SSFA_output.log 2>&1
    python $SSFA_script $bamfile 3R 6900000:7000000 ${SSFAfolder}/3R/Cyp6zm_region/${samplename}_CYP6ZM_SSFA_output.csv 10 > ${SSFAfolder}/3R/Cyp6zm_region/SSFAlogs/${samplename}_CYP6ZM_SSFA_output.log 2>&1
    python $SSFA_script $bamfile 3R 28570000:28620000 ${SSFAfolder}/3R/Gste_region/${samplename}_GST_SSFA_output.csv 10 > ${SSFAfolder}/3R/Gste_region/SSFAlogs/${samplename}_GST_SSFA_output.log 2>&1
    python $SSFA_script $bamfile X 15220000:15255000 ${SSFAfolder}/X/Cyp9k1_region/${samplename}_CYP9K1_SSFA_output.csv 10 > ${SSFAfolder}/X/Cyp9k1_region/SSFAlogs/${samplename}_CYP9K1_SSFA_output.log 2>&1

    # Get the soft clipped reads
    # Runs breakpoint_detector.py for every chrom: This script goes through an alignment file and records the positions at which soft_clipping is detected in the aligned reads
    breakpoints_script=$scriptsfolder/breakpoint_detector.py
    breakpointsfolder=$outputfolder/diagnostic_reads/breakpoints
    python $breakpoints_script $bamfile 2R 3425000:3650000 ${breakpointsfolder}/2R/Ace1_region/${samplename}_Ace1_breakpoints_output 10 > ${breakpointsfolder}/2R/Ace1_region/breakpointlogs/${samplename}_Ace1_breakpoints_output.log 2>&1
    python $breakpoints_script $bamfile 2R 28460000:28570000 ${breakpointsfolder}/2R/Cyp6_region/${samplename}_CYP6_breakpoints_output 10 > ${breakpointsfolder}/2R/Cyp6_region/breakpointlogs/${samplename}_CYP6_breakpoints_output.log 2>&1
    python $breakpoints_script $bamfile 3R 6900000:7000000 ${breakpointsfolder}/3R/Cyp6zm_region/${samplename}_CYP6ZM_breakpoints_output 10 > ${breakpointsfolder}/3R/Cyp6zm_region/breakpointlogs/${samplename}_CYP6ZM_breakpoints_output.log 2>&1
    python $breakpoints_script $bamfile 3R 28570000:28620000 ${breakpointsfolder}/3R/Gste_region/${samplename}_GST_breakpoints_output 10 > ${breakpointsfolder}/3R/Gste_region/breakpointlogs/${samplename}_GST_breakpoints_output.log 2>&1
    python $breakpoints_script $bamfile X 15220000:15255000 ${breakpointsfolder}/X/Cyp9k1_region/${samplename}_CYP9K1_breakpoints_output 10 > ${breakpointsfolder}/X/Cyp9k1_region/breakpointlogs/${samplename}_CYP9K1_breakpoints_output.log 2>&1

  >>>
  runtime {
    docker: docker
    preemptible: preemptible_tries
    cpu: num_cpu
    memory: mem_gb + " GiB"
    disks: "local-disk " + disk_gb + " HDD"
    zones: runtime_zones
  }
  output {
    File diagnostic_reads_tar = # zip of the directory structure for the extract diagnostic reads step
  }
}

task TargetRegionsCNVCalling {
  input {
    File sample_manifest        # manifest: pipeline input
    # gene_coordinates_file
    # metadata
    # species_id_file
    # coverage_variance_file
    # coveragefolder
    File diagnostic_reads_tar   # diagnostic_reads_folder: output of ExtractDiagnosticReads
    # plotting_functions_file
    # ncores

    String project_id
    String output_basename

    String docker # add R docker
    Int num_cpu = 1
    RunTimeSettings runTimeSettings
    Int preemptible_tries = runTimeSettings.preemptible_tries
    String runtime_zones = "us-central1-b"
    Float mem_gb = 3.75
    Int disk_gb = 50
  }


  command <<<
    R-3.6.1 --slave -f $scriptsfolder/target_regions_analysis.r --args $manifest \
      $gene_coordinates_file \
      $metadata \
      $species_id_file \
      $coverage_variance_file \
      $coveragefolder \
      $diagnostic_reads_folder \
      $plotting_functions_file \
      $ncores \
      > target_regions_analysis/target_regions_analysis.log 2>&1
  >>>
  runtime {
    docker: docker
    preemptible: preemptible_tries
    cpu: num_cpu
    memory: mem_gb + " GiB"
    disks: "local-disk " + disk_gb + " HDD"
    zones: runtime_zones
  }
  output {
    File output_file = local_file
    File output_index_file = "~{local_file}.tbi"
  }
}
